{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.875 · Deep Learning · Práctica</p>\n",
    "<p style=\"margin: 0; text-align:right;\">2019-2 · Máster universitario en Ciencia de datos (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# Sistema automático para la detección de COVID-19 en radiografías\n",
    "\n",
    "Una de las aplicaciones de AI es el procesamiendo de imágenes médicas. En particular, el uso de radiografías para una detección no invasiva y rápida del Covid-19 puede resultar extremadamente útil para ayudar y agilizar la tarea del personal médico [1][2].\n",
    "\n",
    "En este proyecto desarrollaremos un detector *Deep Learning* de Covid-19 en radiografías. Para ello, utilizaremos las imágeners de la base de datos \"Covid-chestxray-dataset\" [3], generada por unos investigadores del grupo de investigación [Mila](https://mila.quebec/en/) y de la Universidad de Montreal [4]. También utilizaremos imágenes de radiografías de pacientes sanos y con neumonía bacterial extraídas de la competición de Kaggle \"Chest X-Ray Images (Pneumonia)\" [5].\n",
    "\n",
    "En total, disponemos de una cantidad de 426 imágenes, divididas en conjuntos de entrenamiento (339 imágenes), validación (42 imágenes) y test (45 imágenes).\n",
    "\n",
    "Las particiones se dan en listas \".txt\", en las que a cada imagen se le asigna una etiqueta:\n",
    "- 0) Healthy\n",
    "- 1) Covid-19\n",
    "- 2) Pneumonia\n",
    "\n",
    "El objetivo consisten en desarrollar un sistema basado en redes neuronales capaz de clasificar correctamente las imágenes en estas 3 categorías.\n",
    "\n",
    "**<u>Nota</u>**: Los resultados obtenidos por los modelos entrenados en esta base de datos son puramente para finalidades educativas y no se pueden utilizar para un diagnóstico real sin validación clínica.\n",
    "\n",
    "#### Referencias\n",
    "1. María Climent, 2020 [Covid-19: La Inteligencia Artificial De La Española Quibim Puede Acelerar El Diagnóstico Del Coronavirus](https://innovadores.larazon.es/es/esta-inteligencia-artificial-espanola-puede-acelerar-el-diagnostico-del-coronavirus/)\n",
    "2. Angel Alberich-bayarri,2020 [Imagin, AI and Radiomix to understand and fight Coronavirus Covid-19](https://quibim.com/2020/02/14/imaging-ai-and-radiomics-to-understand-and-fight-coronavirus-covid-19/)\n",
    "3. [Ieee8023/covid-chestxray-dataset](https://github.com/ieee8023/covid-chestxray-dataset)\n",
    "4. Cohen, J.P., Morrison, P. and Dao, L., 2020. [COVID-19 image data collection](https://arxiv.org/pdf/2003.11597.pdf).\n",
    "5. Paul Mooney, 2019 [Chest X-ray Images (pneumonia)](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia)\n",
    "\n",
    "\n",
    "#### Lecturas recomendadas\n",
    "6. Souradip Chakraborty, 2020. [Detection Of Covid-19 Presence from Chest X-ray Scans Using Cnn & Class Activation Maps](https://towardsdatascience.com/detection-of-covid-19-presence-from-chest-x-ray-scans-using-cnn-class-activation-maps-c1ab0d7c294b)\n",
    "\n",
    "7. Cohen, J.P., Hashir, M., Brooks, R. and Bertrand, H., 2020. [On the limits of cross-domain generalization in automated X-ray prediction](https://arxiv.org/pdf/2002.02497.pdf)\n",
    "\n",
    "8. Karim, M., Döhmen, T., Rebholz-Schuhmann, D., Decker, S., Cochez, M. and Beyan, O., 2020. [Deepcovidexplainer: Explainable covid-19 predictions based on chest x-ray images](https://arxiv.org/pdf/2004.04582.pdf).\n",
    "\n",
    "9. Wang, L., Wong, A. (2020). [COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images](https://arxiv.org/abs/2003.09871)\n",
    "\n",
    "10. Zhou, B., Khosla, A., Lapedriza, A., Oliva, A. and Torralba, A., 2016. [Learning deep features for discriminative localization](https://arxiv.org/pdf/1512.04150.pdf). In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 2921-2929).\n",
    "\n",
    "11. Mordvintsev, A., Olah, C. and Tyka, M., 2015. [Inceptionism: Going deeper into neural networks](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación del Dataset (3 puntos)\n",
    "\n",
    "En este primer apartado se analizarán las imágenes de la base de datos y se disñará un *pipeline* para cargar las imágenes y prepararlas para la red neuronal.\n",
    "\n",
    "Se deberán tener en cuenta factores como:\n",
    "- Tamaño de entrada de las imágenes\n",
    "- Normalización de las imágenes\n",
    "- Visualizaciones de algunas muestras de cada categoría\n",
    "- Técnicas de *data augmentation* para aumentar el tamaño del conjunto de entrenamiento\n",
    "\n",
    "Y, en general, cualquier técnica que consideréis que pueda mejorar la implementación y resultados de este proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación del modelo y métricas de evaluación (3 puntos)\n",
    "\n",
    "En esta sección se tiene que desarrollar el *pipeline* para la creación y entrenamiento de el/los modelo/s.\n",
    "\n",
    "Se trabajará con los datos de *training* y de *validación*.\n",
    "\n",
    "Se deberán tener en cuenta aspectos como:\n",
    "- El tipo de arquitectura más adecuado para el problema\n",
    "- Las métricas que se deben utilizar para medir de forma correcta el comportamiento del modelo\n",
    "- Visualizaciones de las curvas de entrenamiento/validación que ayuden a decidir cuál ha sido el mejor modelo.\n",
    "- Considerar un modelo *baseline* para poder comparar las métricas (por ejemplo, utilizar predicciones aleatorias o utilizar un modelo muy sencillo, como por ejemplo una red con muy pocas capas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados y Conclusiones (3 puntos)\n",
    "\n",
    "En esta sección se debe implementar la fase de test de los mejores modelos desarrollados anteriormente.\n",
    "\n",
    "Se valorarán aspectos como:\n",
    "- Razonamiento de qué arquitectura es la más adecuada\n",
    "- Análisis cuantitativo y cualitativo de los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Explainability* (1 punto)\n",
    "\n",
    "Investiga sobre las técnicas que se utilizan para entender las decisiones de una CNN. Por ejemplo, los [Class Activation Maps](https://arxiv.org/pdf/1512.04150.pdf) (CAM)[4] son una modificación en la arquitectura de una CNN de clasificación de imágenes que permite visualizar qué partes de la imagen se consideran para la clasificación de una muestra con una determinada etiqueta. Variaciones de las CAMs se han aplicado recientemente para entender el comportamiento de las redes para detectar Covid-19 [8].\n",
    "\n",
    "Otro método es el popular [Deep Dream](https://deepdreamgenerator.com/)[11]. Este método, a parte de generar imágenes con un estilo artístico/psicodélico, sirve para entender el tipo de características que busca una red en la imagen de entrada para clasificarla con una determinada etiqueta.\n",
    "\n",
    "Implementa alguna técnica de visualización para intentar entender las decisiones de la CNN entrenada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
